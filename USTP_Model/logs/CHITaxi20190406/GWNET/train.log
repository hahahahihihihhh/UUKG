2024-09-25 08:58:28 INFO     Saving logs in: ./logs/CHITaxi20190406\GWNET\
2024-09-25 08:58:28 INFO     ----------------------------------------------------------------------------
2024-09-25 08:58:28 INFO     # 0, Kownledge Graph Embedding: None, Experiment ids: 100
2024-09-25 08:58:28 INFO     ----------------------------------------------------------------------------
2024-09-25 08:58:28 INFO     Begin pipeline, task=traffic_state_pred, model_name=GWNET, dataset_name=CHITaxi20190406, exp_id=100
2024-09-25 08:58:28 INFO     {'task': 'traffic_state_pred', 'model': 'GWNET', 'dataset': 'CHITaxi20190406', 'saved_model': True, 'train': True, 'exp_id': 100, 'max_epoch': 200, 'patience': 15, 'use_early_stop': True, 'cache_dataset': False, 'output_window': 12, 'metrics': ['MAE', 'RMSE'], 'cur_times': 0, 'dataset_class': 'TrafficStatePointDataset', 'executor': 'TrafficStateExecutor', 'evaluator': 'TrafficStateEvaluator', 'dropout': 0.3, 'blocks': 4, 'layers': 2, 'batch_size': 32, 'apt_layer': True, 'gcn_bool': True, 'adjtype': 'doubletransition', 'bidir_adj_mx': False, 'randomadj': True, 'kernel_size': 2, 'nhid': 32, 'residual_channels': 32, 'dilation_channels': 32, 'skip_channels': 256, 'end_channels': 512, 'scaler': 'standard', 'load_external': False, 'normal_external': False, 'ext_scaler': 'none', 'add_time_in_day': False, 'add_day_in_week': False, 'learner': 'adam', 'learning_rate': 0.001, 'lr_decay': False, 'clip_grad_norm': True, 'max_grad_norm': 5, 'use_rel_adj': True, 'use_apt_adj': True, 'num_workers': 0, 'pad_with_last_sample': True, 'train_rate': 0.7, 'eval_rate': 0.1, 'input_window': 12, 'robustness_test': False, 'noise_type': 'gaussian', 'disturb_rate': 0.5, 'noise_mean': [5], 'noise_SD': [10], 'gpu': True, 'gpu_id': 0, 'train_loss': 'none', 'epoch': 0, 'weight_decay': 0, 'lr_epsilon': 1e-08, 'lr_beta1': 0.9, 'lr_beta2': 0.999, 'lr_alpha': 0.99, 'lr_momentum': 0, 'lr_scheduler': 'multisteplr', 'lr_decay_ratio': 0.1, 'steps': [5, 20, 40, 70], 'step_size': 10, 'lr_T_max': 30, 'lr_eta_min': 0, 'lr_patience': 10, 'lr_threshold': 0.0001, 'log_level': 'INFO', 'log_every': 1, 'load_best_epoch': True, 'hyper_tune': False, 'evaluator_mode': 'single', 'save_mode': ['csv'], 'geo': {'including_types': ['Point'], 'Point': {}}, 'rel': {'including_types': ['geo'], 'geo': {'cost': 'num'}}, 'dyna': {'including_types': ['state'], 'state': {'entity_id': 'geo_id', 'traffic_speed': 'num'}}, 'data_col': ['inflow', 'outflow'], 'weight_col': 'cost', 'data_files': ['CHITaxi20190406'], 'geo_file': 'CHITaxi20190406', 'rel_file': 'CHITaxi20190406', 'output_dim': 2, 'time_intervals': 1800, 'init_weight_inf_or_zero': 'inf', 'set_weight_link_or_dist': 'dist', 'calculate_weight_adj': True, 'weight_adj_epsilon': 0.1, 'ke_type': 'area', 'device': device(type='cuda', index=0)}
2024-09-25 08:58:28 INFO     Loaded file CHITaxi20190406.geo, num_nodes=77
2024-09-25 08:58:28 INFO     set_weight_link_or_dist: dist
2024-09-25 08:58:28 INFO     init_weight_inf_or_zero: inf
2024-09-25 08:58:28 INFO     Loaded file CHITaxi20190406.rel, shape=(77, 77)
2024-09-25 08:58:28 INFO     Start Calculate the weight by Gauss kernel!
2024-09-25 08:58:28 INFO     Loading file CHITaxi20190406.dyna
2024-09-25 08:58:28 INFO     Loaded file CHITaxi20190406.dyna, shape=(4368, 77, 2)
2024-09-25 08:58:28 INFO     Dataset created
2024-09-25 08:58:28 INFO     x shape: (4345, 12, 77, 2), y shape: (4345, 12, 77, 2)
2024-09-25 08:58:28 INFO     train	x: (3042, 12, 77, 2), y: (3042, 12, 77, 2)
2024-09-25 08:58:28 INFO     eval	x: (434, 12, 77, 2), y: (434, 12, 77, 2)
2024-09-25 08:58:28 INFO     test	x: (869, 12, 77, 2), y: (869, 12, 77, 2)
2024-09-25 08:58:28 INFO     StandardScaler mean: 11.137838123415046, std: 53.15358218315973
2024-09-25 08:58:28 INFO     NoneScaler
2024-09-25 08:58:31 INFO     add adj_mx to supports
2024-09-25 08:58:31 INFO     add apt_adj(v1 * v2) in forward process
2024-09-25 08:58:31 INFO     receptive_field: 14
2024-09-25 08:58:31 INFO     GWNET(
  (filter_convs): ModuleList(
    (0): Conv2d(32, 32, kernel_size=(1, 2), stride=(1, 1))
    (1): Conv2d(32, 32, kernel_size=(1, 2), stride=(1, 1), dilation=(2, 2))
    (2): Conv2d(32, 32, kernel_size=(1, 2), stride=(1, 1))
    (3): Conv2d(32, 32, kernel_size=(1, 2), stride=(1, 1), dilation=(2, 2))
    (4): Conv2d(32, 32, kernel_size=(1, 2), stride=(1, 1))
    (5): Conv2d(32, 32, kernel_size=(1, 2), stride=(1, 1), dilation=(2, 2))
    (6): Conv2d(32, 32, kernel_size=(1, 2), stride=(1, 1))
    (7): Conv2d(32, 32, kernel_size=(1, 2), stride=(1, 1), dilation=(2, 2))
  )
  (gate_convs): ModuleList(
    (0): Conv1d(32, 32, kernel_size=(1, 2), stride=(1,))
    (1): Conv1d(32, 32, kernel_size=(1, 2), stride=(1,), dilation=(2,))
    (2): Conv1d(32, 32, kernel_size=(1, 2), stride=(1,))
    (3): Conv1d(32, 32, kernel_size=(1, 2), stride=(1,), dilation=(2,))
    (4): Conv1d(32, 32, kernel_size=(1, 2), stride=(1,))
    (5): Conv1d(32, 32, kernel_size=(1, 2), stride=(1,), dilation=(2,))
    (6): Conv1d(32, 32, kernel_size=(1, 2), stride=(1,))
    (7): Conv1d(32, 32, kernel_size=(1, 2), stride=(1,), dilation=(2,))
  )
  (residual_convs): ModuleList(
    (0): Conv1d(32, 32, kernel_size=(1, 1), stride=(1,))
    (1): Conv1d(32, 32, kernel_size=(1, 1), stride=(1,))
    (2): Conv1d(32, 32, kernel_size=(1, 1), stride=(1,))
    (3): Conv1d(32, 32, kernel_size=(1, 1), stride=(1,))
    (4): Conv1d(32, 32, kernel_size=(1, 1), stride=(1,))
    (5): Conv1d(32, 32, kernel_size=(1, 1), stride=(1,))
    (6): Conv1d(32, 32, kernel_size=(1, 1), stride=(1,))
    (7): Conv1d(32, 32, kernel_size=(1, 1), stride=(1,))
  )
  (skip_convs): ModuleList(
    (0): Conv1d(32, 256, kernel_size=(1, 1), stride=(1,))
    (1): Conv1d(32, 256, kernel_size=(1, 1), stride=(1,))
    (2): Conv1d(32, 256, kernel_size=(1, 1), stride=(1,))
    (3): Conv1d(32, 256, kernel_size=(1, 1), stride=(1,))
    (4): Conv1d(32, 256, kernel_size=(1, 1), stride=(1,))
    (5): Conv1d(32, 256, kernel_size=(1, 1), stride=(1,))
    (6): Conv1d(32, 256, kernel_size=(1, 1), stride=(1,))
    (7): Conv1d(32, 256, kernel_size=(1, 1), stride=(1,))
  )
  (bn): ModuleList(
    (0): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (gconv): ModuleList(
    (0): GCN(
      (nconv): NConv()
      (mlp): Linear(
        (mlp): Conv2d(224, 32, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (1): GCN(
      (nconv): NConv()
      (mlp): Linear(
        (mlp): Conv2d(224, 32, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (2): GCN(
      (nconv): NConv()
      (mlp): Linear(
        (mlp): Conv2d(224, 32, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (3): GCN(
      (nconv): NConv()
      (mlp): Linear(
        (mlp): Conv2d(224, 32, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (4): GCN(
      (nconv): NConv()
      (mlp): Linear(
        (mlp): Conv2d(224, 32, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (5): GCN(
      (nconv): NConv()
      (mlp): Linear(
        (mlp): Conv2d(224, 32, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (6): GCN(
      (nconv): NConv()
      (mlp): Linear(
        (mlp): Conv2d(224, 32, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (7): GCN(
      (nconv): NConv()
      (mlp): Linear(
        (mlp): Conv2d(224, 32, kernel_size=(1, 1), stride=(1, 1))
      )
    )
  )
  (start_conv): Conv2d(2, 32, kernel_size=(1, 1), stride=(1, 1))
  (end_conv_1): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))
  (end_conv_2): Conv2d(512, 12, kernel_size=(1, 1), stride=(1, 1))
)
2024-09-25 08:58:31 INFO     nodevec1	torch.Size([77, 10])	cuda:0	True
2024-09-25 08:58:31 INFO     nodevec2	torch.Size([10, 77])	cuda:0	True
2024-09-25 08:58:31 INFO     filter_convs.0.weight	torch.Size([32, 32, 1, 2])	cuda:0	True
2024-09-25 08:58:31 INFO     filter_convs.0.bias	torch.Size([32])	cuda:0	True
2024-09-25 08:58:31 INFO     filter_convs.1.weight	torch.Size([32, 32, 1, 2])	cuda:0	True
2024-09-25 08:58:31 INFO     filter_convs.1.bias	torch.Size([32])	cuda:0	True
2024-09-25 08:58:31 INFO     filter_convs.2.weight	torch.Size([32, 32, 1, 2])	cuda:0	True
2024-09-25 08:58:31 INFO     filter_convs.2.bias	torch.Size([32])	cuda:0	True
2024-09-25 08:58:31 INFO     filter_convs.3.weight	torch.Size([32, 32, 1, 2])	cuda:0	True
2024-09-25 08:58:31 INFO     filter_convs.3.bias	torch.Size([32])	cuda:0	True
2024-09-25 08:58:31 INFO     filter_convs.4.weight	torch.Size([32, 32, 1, 2])	cuda:0	True
2024-09-25 08:58:31 INFO     filter_convs.4.bias	torch.Size([32])	cuda:0	True
2024-09-25 08:58:31 INFO     filter_convs.5.weight	torch.Size([32, 32, 1, 2])	cuda:0	True
2024-09-25 08:58:31 INFO     filter_convs.5.bias	torch.Size([32])	cuda:0	True
2024-09-25 08:58:31 INFO     filter_convs.6.weight	torch.Size([32, 32, 1, 2])	cuda:0	True
2024-09-25 08:58:31 INFO     filter_convs.6.bias	torch.Size([32])	cuda:0	True
2024-09-25 08:58:31 INFO     filter_convs.7.weight	torch.Size([32, 32, 1, 2])	cuda:0	True
2024-09-25 08:58:31 INFO     filter_convs.7.bias	torch.Size([32])	cuda:0	True
2024-09-25 08:58:31 INFO     gate_convs.0.weight	torch.Size([32, 32, 1, 2])	cuda:0	True
2024-09-25 08:58:31 INFO     gate_convs.0.bias	torch.Size([32])	cuda:0	True
2024-09-25 08:58:31 INFO     gate_convs.1.weight	torch.Size([32, 32, 1, 2])	cuda:0	True
2024-09-25 08:58:31 INFO     gate_convs.1.bias	torch.Size([32])	cuda:0	True
2024-09-25 08:58:31 INFO     gate_convs.2.weight	torch.Size([32, 32, 1, 2])	cuda:0	True
2024-09-25 08:58:31 INFO     gate_convs.2.bias	torch.Size([32])	cuda:0	True
2024-09-25 08:58:31 INFO     gate_convs.3.weight	torch.Size([32, 32, 1, 2])	cuda:0	True
2024-09-25 08:58:31 INFO     gate_convs.3.bias	torch.Size([32])	cuda:0	True
2024-09-25 08:58:31 INFO     gate_convs.4.weight	torch.Size([32, 32, 1, 2])	cuda:0	True
2024-09-25 08:58:31 INFO     gate_convs.4.bias	torch.Size([32])	cuda:0	True
2024-09-25 08:58:31 INFO     gate_convs.5.weight	torch.Size([32, 32, 1, 2])	cuda:0	True
2024-09-25 08:58:31 INFO     gate_convs.5.bias	torch.Size([32])	cuda:0	True
2024-09-25 08:58:31 INFO     gate_convs.6.weight	torch.Size([32, 32, 1, 2])	cuda:0	True
2024-09-25 08:58:31 INFO     gate_convs.6.bias	torch.Size([32])	cuda:0	True
2024-09-25 08:58:31 INFO     gate_convs.7.weight	torch.Size([32, 32, 1, 2])	cuda:0	True
2024-09-25 08:58:31 INFO     gate_convs.7.bias	torch.Size([32])	cuda:0	True
2024-09-25 08:58:31 INFO     residual_convs.0.weight	torch.Size([32, 32, 1, 1])	cuda:0	True
2024-09-25 08:58:31 INFO     residual_convs.0.bias	torch.Size([32])	cuda:0	True
2024-09-25 08:58:31 INFO     residual_convs.1.weight	torch.Size([32, 32, 1, 1])	cuda:0	True
2024-09-25 08:58:31 INFO     residual_convs.1.bias	torch.Size([32])	cuda:0	True
2024-09-25 08:58:31 INFO     residual_convs.2.weight	torch.Size([32, 32, 1, 1])	cuda:0	True
2024-09-25 08:58:31 INFO     residual_convs.2.bias	torch.Size([32])	cuda:0	True
2024-09-25 08:58:31 INFO     residual_convs.3.weight	torch.Size([32, 32, 1, 1])	cuda:0	True
2024-09-25 08:58:31 INFO     residual_convs.3.bias	torch.Size([32])	cuda:0	True
2024-09-25 08:58:31 INFO     residual_convs.4.weight	torch.Size([32, 32, 1, 1])	cuda:0	True
2024-09-25 08:58:31 INFO     residual_convs.4.bias	torch.Size([32])	cuda:0	True
2024-09-25 08:58:31 INFO     residual_convs.5.weight	torch.Size([32, 32, 1, 1])	cuda:0	True
2024-09-25 08:58:31 INFO     residual_convs.5.bias	torch.Size([32])	cuda:0	True
2024-09-25 08:58:31 INFO     residual_convs.6.weight	torch.Size([32, 32, 1, 1])	cuda:0	True
2024-09-25 08:58:31 INFO     residual_convs.6.bias	torch.Size([32])	cuda:0	True
2024-09-25 08:58:31 INFO     residual_convs.7.weight	torch.Size([32, 32, 1, 1])	cuda:0	True
2024-09-25 08:58:31 INFO     residual_convs.7.bias	torch.Size([32])	cuda:0	True
2024-09-25 08:58:31 INFO     skip_convs.0.weight	torch.Size([256, 32, 1, 1])	cuda:0	True
2024-09-25 08:58:31 INFO     skip_convs.0.bias	torch.Size([256])	cuda:0	True
2024-09-25 08:58:31 INFO     skip_convs.1.weight	torch.Size([256, 32, 1, 1])	cuda:0	True
2024-09-25 08:58:31 INFO     skip_convs.1.bias	torch.Size([256])	cuda:0	True
2024-09-25 08:58:31 INFO     skip_convs.2.weight	torch.Size([256, 32, 1, 1])	cuda:0	True
2024-09-25 08:58:31 INFO     skip_convs.2.bias	torch.Size([256])	cuda:0	True
2024-09-25 08:58:31 INFO     skip_convs.3.weight	torch.Size([256, 32, 1, 1])	cuda:0	True
2024-09-25 08:58:31 INFO     skip_convs.3.bias	torch.Size([256])	cuda:0	True
2024-09-25 08:58:31 INFO     skip_convs.4.weight	torch.Size([256, 32, 1, 1])	cuda:0	True
2024-09-25 08:58:31 INFO     skip_convs.4.bias	torch.Size([256])	cuda:0	True
2024-09-25 08:58:31 INFO     skip_convs.5.weight	torch.Size([256, 32, 1, 1])	cuda:0	True
2024-09-25 08:58:31 INFO     skip_convs.5.bias	torch.Size([256])	cuda:0	True
2024-09-25 08:58:31 INFO     skip_convs.6.weight	torch.Size([256, 32, 1, 1])	cuda:0	True
2024-09-25 08:58:31 INFO     skip_convs.6.bias	torch.Size([256])	cuda:0	True
2024-09-25 08:58:31 INFO     skip_convs.7.weight	torch.Size([256, 32, 1, 1])	cuda:0	True
2024-09-25 08:58:31 INFO     skip_convs.7.bias	torch.Size([256])	cuda:0	True
2024-09-25 08:58:31 INFO     bn.0.weight	torch.Size([32])	cuda:0	True
2024-09-25 08:58:31 INFO     bn.0.bias	torch.Size([32])	cuda:0	True
2024-09-25 08:58:31 INFO     bn.1.weight	torch.Size([32])	cuda:0	True
2024-09-25 08:58:31 INFO     bn.1.bias	torch.Size([32])	cuda:0	True
2024-09-25 08:58:31 INFO     bn.2.weight	torch.Size([32])	cuda:0	True
2024-09-25 08:58:31 INFO     bn.2.bias	torch.Size([32])	cuda:0	True
2024-09-25 08:58:31 INFO     bn.3.weight	torch.Size([32])	cuda:0	True
2024-09-25 08:58:31 INFO     bn.3.bias	torch.Size([32])	cuda:0	True
2024-09-25 08:58:31 INFO     bn.4.weight	torch.Size([32])	cuda:0	True
2024-09-25 08:58:31 INFO     bn.4.bias	torch.Size([32])	cuda:0	True
2024-09-25 08:58:31 INFO     bn.5.weight	torch.Size([32])	cuda:0	True
2024-09-25 08:58:31 INFO     bn.5.bias	torch.Size([32])	cuda:0	True
2024-09-25 08:58:31 INFO     bn.6.weight	torch.Size([32])	cuda:0	True
2024-09-25 08:58:31 INFO     bn.6.bias	torch.Size([32])	cuda:0	True
2024-09-25 08:58:31 INFO     bn.7.weight	torch.Size([32])	cuda:0	True
2024-09-25 08:58:31 INFO     bn.7.bias	torch.Size([32])	cuda:0	True
2024-09-25 08:58:31 INFO     gconv.0.mlp.mlp.weight	torch.Size([32, 224, 1, 1])	cuda:0	True
2024-09-25 08:58:31 INFO     gconv.0.mlp.mlp.bias	torch.Size([32])	cuda:0	True
2024-09-25 08:58:31 INFO     gconv.1.mlp.mlp.weight	torch.Size([32, 224, 1, 1])	cuda:0	True
2024-09-25 08:58:31 INFO     gconv.1.mlp.mlp.bias	torch.Size([32])	cuda:0	True
2024-09-25 08:58:31 INFO     gconv.2.mlp.mlp.weight	torch.Size([32, 224, 1, 1])	cuda:0	True
2024-09-25 08:58:31 INFO     gconv.2.mlp.mlp.bias	torch.Size([32])	cuda:0	True
2024-09-25 08:58:31 INFO     gconv.3.mlp.mlp.weight	torch.Size([32, 224, 1, 1])	cuda:0	True
2024-09-25 08:58:31 INFO     gconv.3.mlp.mlp.bias	torch.Size([32])	cuda:0	True
2024-09-25 08:58:31 INFO     gconv.4.mlp.mlp.weight	torch.Size([32, 224, 1, 1])	cuda:0	True
2024-09-25 08:58:31 INFO     gconv.4.mlp.mlp.bias	torch.Size([32])	cuda:0	True
2024-09-25 08:58:31 INFO     gconv.5.mlp.mlp.weight	torch.Size([32, 224, 1, 1])	cuda:0	True
2024-09-25 08:58:31 INFO     gconv.5.mlp.mlp.bias	torch.Size([32])	cuda:0	True
2024-09-25 08:58:31 INFO     gconv.6.mlp.mlp.weight	torch.Size([32, 224, 1, 1])	cuda:0	True
2024-09-25 08:58:31 INFO     gconv.6.mlp.mlp.bias	torch.Size([32])	cuda:0	True
2024-09-25 08:58:31 INFO     gconv.7.mlp.mlp.weight	torch.Size([32, 224, 1, 1])	cuda:0	True
2024-09-25 08:58:31 INFO     gconv.7.mlp.mlp.bias	torch.Size([32])	cuda:0	True
2024-09-25 08:58:31 INFO     start_conv.weight	torch.Size([32, 2, 1, 1])	cuda:0	True
2024-09-25 08:58:31 INFO     start_conv.bias	torch.Size([32])	cuda:0	True
2024-09-25 08:58:31 INFO     end_conv_1.weight	torch.Size([512, 256, 1, 1])	cuda:0	True
2024-09-25 08:58:31 INFO     end_conv_1.bias	torch.Size([512])	cuda:0	True
2024-09-25 08:58:31 INFO     end_conv_2.weight	torch.Size([12, 512, 1, 1])	cuda:0	True
2024-09-25 08:58:31 INFO     end_conv_2.bias	torch.Size([12])	cuda:0	True
2024-09-25 08:58:31 INFO     Total parameter numbers: 306800
2024-09-25 08:58:31 INFO     You select `adam` optimizer.
2024-09-25 08:58:31 WARNING  Received none train loss func and will use the loss func defined in the model.
2024-09-25 08:58:31 INFO     Start training ...
2024-09-25 08:58:31 INFO     num_batches:96
2024-09-25 08:59:12 INFO     epoch complete!
2024-09-25 08:59:12 INFO     evaluating now!
2024-09-25 08:59:17 INFO     Epoch [0/200] train_loss: 12.3997, val_loss: 10.1289, lr: 0.001000, 45.07s
2024-09-25 08:59:17 INFO     Saved model at 0
2024-09-25 08:59:17 INFO     Val loss decrease from inf to 10.1289, saving to ./libcity/cache/100/model_cache/GWNET_CHITaxi20190406_epoch0.tar
2024-09-25 08:59:53 INFO     epoch complete!
2024-09-25 08:59:53 INFO     evaluating now!
2024-09-25 08:59:58 INFO     Epoch [1/200] train_loss: 9.3300, val_loss: 8.8915, lr: 0.001000, 41.22s
2024-09-25 08:59:58 INFO     Saved model at 1
2024-09-25 08:59:58 INFO     Val loss decrease from 10.1289 to 8.8915, saving to ./libcity/cache/100/model_cache/GWNET_CHITaxi20190406_epoch1.tar
2024-09-25 09:00:33 INFO     epoch complete!
2024-09-25 09:00:33 INFO     evaluating now!
2024-09-25 09:00:38 INFO     Epoch [2/200] train_loss: 8.4563, val_loss: 8.1999, lr: 0.001000, 40.50s
2024-09-25 09:00:38 INFO     Saved model at 2
2024-09-25 09:00:38 INFO     Val loss decrease from 8.8915 to 8.1999, saving to ./libcity/cache/100/model_cache/GWNET_CHITaxi20190406_epoch2.tar
2024-09-25 09:01:13 INFO     epoch complete!
2024-09-25 09:01:13 INFO     evaluating now!
2024-09-25 09:01:19 INFO     Epoch [3/200] train_loss: 8.2420, val_loss: 7.8986, lr: 0.001000, 41.09s
2024-09-25 09:01:19 INFO     Saved model at 3
2024-09-25 09:01:19 INFO     Val loss decrease from 8.1999 to 7.8986, saving to ./libcity/cache/100/model_cache/GWNET_CHITaxi20190406_epoch3.tar
2024-09-25 09:02:03 INFO     epoch complete!
2024-09-25 09:02:03 INFO     evaluating now!
2024-09-25 09:02:10 INFO     Epoch [4/200] train_loss: 7.7821, val_loss: 7.7247, lr: 0.001000, 50.07s
2024-09-25 09:02:10 INFO     Saved model at 4
2024-09-25 09:02:10 INFO     Val loss decrease from 7.8986 to 7.7247, saving to ./libcity/cache/100/model_cache/GWNET_CHITaxi20190406_epoch4.tar
2024-09-25 09:02:54 INFO     epoch complete!
2024-09-25 09:02:54 INFO     evaluating now!
2024-09-25 09:03:01 INFO     Epoch [5/200] train_loss: 7.8234, val_loss: 8.7137, lr: 0.001000, 51.47s
2024-09-25 09:03:45 INFO     epoch complete!
2024-09-25 09:03:45 INFO     evaluating now!
2024-09-25 09:03:52 INFO     Epoch [6/200] train_loss: 7.6096, val_loss: 7.3459, lr: 0.001000, 50.60s
2024-09-25 09:03:52 INFO     Saved model at 6
2024-09-25 09:03:52 INFO     Val loss decrease from 7.7247 to 7.3459, saving to ./libcity/cache/100/model_cache/GWNET_CHITaxi20190406_epoch6.tar
2024-09-25 09:04:34 INFO     epoch complete!
2024-09-25 09:04:34 INFO     evaluating now!
2024-09-25 09:04:40 INFO     Epoch [7/200] train_loss: 7.4850, val_loss: 9.2106, lr: 0.001000, 48.74s
2024-09-25 09:05:15 INFO     epoch complete!
2024-09-25 09:05:15 INFO     evaluating now!
2024-09-25 09:05:19 INFO     Epoch [8/200] train_loss: 7.3549, val_loss: 6.8963, lr: 0.001000, 38.89s
2024-09-25 09:05:19 INFO     Saved model at 8
2024-09-25 09:05:19 INFO     Val loss decrease from 7.3459 to 6.8963, saving to ./libcity/cache/100/model_cache/GWNET_CHITaxi20190406_epoch8.tar
2024-09-25 09:05:54 INFO     epoch complete!
2024-09-25 09:05:54 INFO     evaluating now!
2024-09-25 09:05:58 INFO     Epoch [9/200] train_loss: 6.2786, val_loss: 6.8924, lr: 0.001000, 38.88s
2024-09-25 09:05:58 INFO     Saved model at 9
2024-09-25 09:05:58 INFO     Val loss decrease from 6.8963 to 6.8924, saving to ./libcity/cache/100/model_cache/GWNET_CHITaxi20190406_epoch9.tar
2024-09-25 09:06:38 INFO     epoch complete!
2024-09-25 09:06:38 INFO     evaluating now!
2024-09-25 09:06:43 INFO     Epoch [10/200] train_loss: 5.9551, val_loss: 6.7999, lr: 0.001000, 44.40s
2024-09-25 09:06:43 INFO     Saved model at 10
2024-09-25 09:06:43 INFO     Val loss decrease from 6.8924 to 6.7999, saving to ./libcity/cache/100/model_cache/GWNET_CHITaxi20190406_epoch10.tar
2024-09-25 09:07:22 INFO     epoch complete!
2024-09-25 09:07:22 INFO     evaluating now!
2024-09-25 09:07:28 INFO     Epoch [11/200] train_loss: 5.7674, val_loss: 5.4224, lr: 0.001000, 45.29s
2024-09-25 09:07:28 INFO     Saved model at 11
2024-09-25 09:07:28 INFO     Val loss decrease from 6.7999 to 5.4224, saving to ./libcity/cache/100/model_cache/GWNET_CHITaxi20190406_epoch11.tar
2024-09-25 09:08:09 INFO     epoch complete!
2024-09-25 09:08:09 INFO     evaluating now!
2024-09-25 09:08:15 INFO     Epoch [12/200] train_loss: 5.5612, val_loss: 5.6026, lr: 0.001000, 47.00s
2024-09-25 09:08:56 INFO     epoch complete!
2024-09-25 09:08:56 INFO     evaluating now!
2024-09-25 09:09:02 INFO     Epoch [13/200] train_loss: 5.4359, val_loss: 5.4968, lr: 0.001000, 46.68s
2024-09-25 09:09:40 INFO     epoch complete!
2024-09-25 09:09:40 INFO     evaluating now!
2024-09-25 09:09:46 INFO     Epoch [14/200] train_loss: 5.3393, val_loss: 7.9874, lr: 0.001000, 44.00s
2024-09-25 09:10:27 INFO     epoch complete!
2024-09-25 09:10:27 INFO     evaluating now!
2024-09-25 09:10:33 INFO     Epoch [15/200] train_loss: 5.4515, val_loss: 7.6969, lr: 0.001000, 47.07s
2024-09-25 09:11:14 INFO     epoch complete!
2024-09-25 09:11:14 INFO     evaluating now!
2024-09-25 09:11:20 INFO     Epoch [16/200] train_loss: 5.2492, val_loss: 6.2260, lr: 0.001000, 46.94s
2024-09-25 09:11:59 INFO     epoch complete!
2024-09-25 09:11:59 INFO     evaluating now!
2024-09-25 09:12:04 INFO     Epoch [17/200] train_loss: 5.0677, val_loss: 5.2140, lr: 0.001000, 44.79s
2024-09-25 09:12:04 INFO     Saved model at 17
2024-09-25 09:12:04 INFO     Val loss decrease from 5.4224 to 5.2140, saving to ./libcity/cache/100/model_cache/GWNET_CHITaxi20190406_epoch17.tar
2024-09-25 09:12:46 INFO     epoch complete!
2024-09-25 09:12:46 INFO     evaluating now!
2024-09-25 09:12:52 INFO     Epoch [18/200] train_loss: 5.0187, val_loss: 5.3093, lr: 0.001000, 47.44s
2024-09-25 09:13:34 INFO     epoch complete!
2024-09-25 09:13:34 INFO     evaluating now!
2024-09-25 09:13:40 INFO     Epoch [19/200] train_loss: 4.9774, val_loss: 5.4086, lr: 0.001000, 48.01s
2024-09-25 09:14:20 INFO     epoch complete!
2024-09-25 09:14:20 INFO     evaluating now!
2024-09-25 09:14:25 INFO     Epoch [20/200] train_loss: 4.9293, val_loss: 6.5149, lr: 0.001000, 45.64s
2024-09-25 09:15:07 INFO     epoch complete!
2024-09-25 09:15:07 INFO     evaluating now!
2024-09-25 09:15:13 INFO     Epoch [21/200] train_loss: 4.9044, val_loss: 6.4819, lr: 0.001000, 47.22s
2024-09-25 09:15:53 INFO     epoch complete!
2024-09-25 09:15:53 INFO     evaluating now!
2024-09-25 09:15:59 INFO     Epoch [22/200] train_loss: 4.8910, val_loss: 5.9104, lr: 0.001000, 46.43s
2024-09-25 09:16:39 INFO     epoch complete!
2024-09-25 09:16:39 INFO     evaluating now!
2024-09-25 09:16:46 INFO     Epoch [23/200] train_loss: 4.8314, val_loss: 5.3757, lr: 0.001000, 47.19s
2024-09-25 09:17:27 INFO     epoch complete!
2024-09-25 09:17:27 INFO     evaluating now!
2024-09-25 09:17:34 INFO     Epoch [24/200] train_loss: 4.8673, val_loss: 5.7674, lr: 0.001000, 47.64s
2024-09-25 09:18:17 INFO     epoch complete!
2024-09-25 09:18:17 INFO     evaluating now!
2024-09-25 09:18:21 INFO     Epoch [25/200] train_loss: 4.7652, val_loss: 5.9845, lr: 0.001000, 47.45s
2024-09-25 09:19:02 INFO     epoch complete!
2024-09-25 09:19:02 INFO     evaluating now!
2024-09-25 09:19:07 INFO     Epoch [26/200] train_loss: 4.7459, val_loss: 5.2614, lr: 0.001000, 45.10s
2024-09-25 09:19:48 INFO     epoch complete!
2024-09-25 09:19:48 INFO     evaluating now!
2024-09-25 09:19:54 INFO     Epoch [27/200] train_loss: 4.7018, val_loss: 6.3117, lr: 0.001000, 47.54s
2024-09-25 09:20:36 INFO     epoch complete!
2024-09-25 09:20:36 INFO     evaluating now!
2024-09-25 09:20:42 INFO     Epoch [28/200] train_loss: 4.7244, val_loss: 5.1849, lr: 0.001000, 47.88s
2024-09-25 09:20:42 INFO     Saved model at 28
2024-09-25 09:20:42 INFO     Val loss decrease from 5.2140 to 5.1849, saving to ./libcity/cache/100/model_cache/GWNET_CHITaxi20190406_epoch28.tar
2024-09-25 09:21:25 INFO     epoch complete!
2024-09-25 09:21:25 INFO     evaluating now!
2024-09-25 09:21:29 INFO     Epoch [29/200] train_loss: 4.6726, val_loss: 5.1951, lr: 0.001000, 47.31s
2024-09-25 09:22:14 INFO     epoch complete!
2024-09-25 09:22:14 INFO     evaluating now!
2024-09-25 09:22:20 INFO     Epoch [30/200] train_loss: 4.5585, val_loss: 5.4559, lr: 0.001000, 50.33s
2024-09-25 09:23:02 INFO     epoch complete!
2024-09-25 09:23:02 INFO     evaluating now!
2024-09-25 09:23:08 INFO     Epoch [31/200] train_loss: 4.4965, val_loss: 5.3586, lr: 0.001000, 48.61s
2024-09-25 09:23:51 INFO     epoch complete!
2024-09-25 09:23:51 INFO     evaluating now!
2024-09-25 09:23:55 INFO     Epoch [32/200] train_loss: 4.5637, val_loss: 5.9616, lr: 0.001000, 46.96s
2024-09-25 09:24:39 INFO     epoch complete!
2024-09-25 09:24:39 INFO     evaluating now!
2024-09-25 09:24:45 INFO     Epoch [33/200] train_loss: 4.4956, val_loss: 5.3207, lr: 0.001000, 49.83s
2024-09-25 09:25:30 INFO     epoch complete!
2024-09-25 09:25:30 INFO     evaluating now!
2024-09-25 09:25:36 INFO     Epoch [34/200] train_loss: 4.4716, val_loss: 4.8744, lr: 0.001000, 50.87s
2024-09-25 09:25:36 INFO     Saved model at 34
2024-09-25 09:25:36 INFO     Val loss decrease from 5.1849 to 4.8744, saving to ./libcity/cache/100/model_cache/GWNET_CHITaxi20190406_epoch34.tar
2024-09-25 09:26:21 INFO     epoch complete!
2024-09-25 09:26:21 INFO     evaluating now!
2024-09-25 09:26:28 INFO     Epoch [35/200] train_loss: 4.4038, val_loss: 5.3623, lr: 0.001000, 51.90s
2024-09-25 09:27:13 INFO     epoch complete!
2024-09-25 09:27:13 INFO     evaluating now!
2024-09-25 09:27:19 INFO     Epoch [36/200] train_loss: 4.4050, val_loss: 5.1064, lr: 0.001000, 51.03s
2024-09-25 09:28:02 INFO     epoch complete!
2024-09-25 09:28:02 INFO     evaluating now!
2024-09-25 09:28:08 INFO     Epoch [37/200] train_loss: 4.4206, val_loss: 5.1292, lr: 0.001000, 49.59s
2024-09-25 09:28:53 INFO     epoch complete!
2024-09-25 09:28:53 INFO     evaluating now!
2024-09-25 09:29:00 INFO     Epoch [38/200] train_loss: 4.3890, val_loss: 5.7092, lr: 0.001000, 51.89s
2024-09-25 09:29:42 INFO     epoch complete!
2024-09-25 09:29:42 INFO     evaluating now!
2024-09-25 09:29:48 INFO     Epoch [39/200] train_loss: 4.3401, val_loss: 4.9635, lr: 0.001000, 47.48s
2024-09-25 09:30:32 INFO     epoch complete!
2024-09-25 09:30:32 INFO     evaluating now!
2024-09-25 09:30:39 INFO     Epoch [40/200] train_loss: 4.3523, val_loss: 4.9371, lr: 0.001000, 50.90s
2024-09-25 09:31:24 INFO     epoch complete!
2024-09-25 09:31:24 INFO     evaluating now!
2024-09-25 09:31:31 INFO     Epoch [41/200] train_loss: 4.3325, val_loss: 5.1099, lr: 0.001000, 51.87s
2024-09-25 09:32:16 INFO     epoch complete!
2024-09-25 09:32:16 INFO     evaluating now!
2024-09-25 09:32:22 INFO     Epoch [42/200] train_loss: 4.3330, val_loss: 5.0911, lr: 0.001000, 51.70s
2024-09-25 09:33:08 INFO     epoch complete!
2024-09-25 09:33:08 INFO     evaluating now!
2024-09-25 09:33:14 INFO     Epoch [43/200] train_loss: 4.2838, val_loss: 4.9839, lr: 0.001000, 51.69s
2024-09-25 09:33:59 INFO     epoch complete!
2024-09-25 09:33:59 INFO     evaluating now!
2024-09-25 09:34:05 INFO     Epoch [44/200] train_loss: 4.2253, val_loss: 5.0398, lr: 0.001000, 51.00s
2024-09-25 09:34:50 INFO     epoch complete!
2024-09-25 09:34:50 INFO     evaluating now!
2024-09-25 09:34:58 INFO     Epoch [45/200] train_loss: 4.2454, val_loss: 4.9032, lr: 0.001000, 52.87s
2024-09-25 09:35:43 INFO     epoch complete!
2024-09-25 09:35:43 INFO     evaluating now!
2024-09-25 09:35:50 INFO     Epoch [46/200] train_loss: 4.2101, val_loss: 5.3782, lr: 0.001000, 51.68s
2024-09-25 09:36:34 INFO     epoch complete!
2024-09-25 09:36:34 INFO     evaluating now!
2024-09-25 09:36:40 INFO     Epoch [47/200] train_loss: 4.2362, val_loss: 4.8596, lr: 0.001000, 50.35s
2024-09-25 09:36:40 INFO     Saved model at 47
2024-09-25 09:36:40 INFO     Val loss decrease from 4.8744 to 4.8596, saving to ./libcity/cache/100/model_cache/GWNET_CHITaxi20190406_epoch47.tar
2024-09-25 09:37:23 INFO     epoch complete!
2024-09-25 09:37:23 INFO     evaluating now!
2024-09-25 09:37:29 INFO     Epoch [48/200] train_loss: 4.2234, val_loss: 5.4914, lr: 0.001000, 49.39s
2024-09-25 09:38:12 INFO     epoch complete!
2024-09-25 09:38:12 INFO     evaluating now!
2024-09-25 09:38:18 INFO     Epoch [49/200] train_loss: 4.1661, val_loss: 5.0628, lr: 0.001000, 48.66s
2024-09-25 09:39:01 INFO     epoch complete!
2024-09-25 09:39:01 INFO     evaluating now!
2024-09-25 09:39:08 INFO     Epoch [50/200] train_loss: 4.1248, val_loss: 7.0583, lr: 0.001000, 49.72s
2024-09-25 09:39:50 INFO     epoch complete!
2024-09-25 09:39:50 INFO     evaluating now!
2024-09-25 09:39:56 INFO     Epoch [51/200] train_loss: 4.1231, val_loss: 4.8736, lr: 0.001000, 47.86s
2024-09-25 09:40:40 INFO     epoch complete!
2024-09-25 09:40:40 INFO     evaluating now!
2024-09-25 09:40:47 INFO     Epoch [52/200] train_loss: 4.1014, val_loss: 4.8587, lr: 0.001000, 51.28s
2024-09-25 09:40:47 INFO     Saved model at 52
2024-09-25 09:40:47 INFO     Val loss decrease from 4.8596 to 4.8587, saving to ./libcity/cache/100/model_cache/GWNET_CHITaxi20190406_epoch52.tar
2024-09-25 09:41:31 INFO     epoch complete!
2024-09-25 09:41:31 INFO     evaluating now!
2024-09-25 09:41:38 INFO     Epoch [53/200] train_loss: 4.1026, val_loss: 5.0931, lr: 0.001000, 50.75s
2024-09-25 09:42:17 INFO     epoch complete!
2024-09-25 09:42:17 INFO     evaluating now!
2024-09-25 09:42:22 INFO     Epoch [54/200] train_loss: 4.1463, val_loss: 4.7681, lr: 0.001000, 44.35s
2024-09-25 09:42:22 INFO     Saved model at 54
2024-09-25 09:42:22 INFO     Val loss decrease from 4.8587 to 4.7681, saving to ./libcity/cache/100/model_cache/GWNET_CHITaxi20190406_epoch54.tar
2024-09-25 09:43:07 INFO     epoch complete!
2024-09-25 09:43:07 INFO     evaluating now!
2024-09-25 09:43:14 INFO     Epoch [55/200] train_loss: 4.0612, val_loss: 4.9362, lr: 0.001000, 52.10s
2024-09-25 09:43:57 INFO     epoch complete!
2024-09-25 09:43:57 INFO     evaluating now!
2024-09-25 09:44:04 INFO     Epoch [56/200] train_loss: 4.0876, val_loss: 5.3383, lr: 0.001000, 49.78s
2024-09-25 09:44:49 INFO     epoch complete!
2024-09-25 09:44:49 INFO     evaluating now!
2024-09-25 09:44:56 INFO     Epoch [57/200] train_loss: 4.0615, val_loss: 5.2500, lr: 0.001000, 51.96s
2024-09-25 09:45:44 INFO     epoch complete!
2024-09-25 09:45:44 INFO     evaluating now!
2024-09-25 09:45:50 INFO     Epoch [58/200] train_loss: 4.0480, val_loss: 5.4911, lr: 0.001000, 54.64s
2024-09-25 09:46:35 INFO     epoch complete!
2024-09-25 09:46:35 INFO     evaluating now!
2024-09-25 09:46:42 INFO     Epoch [59/200] train_loss: 4.0102, val_loss: 5.0419, lr: 0.001000, 51.90s
2024-09-25 09:47:29 INFO     epoch complete!
2024-09-25 09:47:29 INFO     evaluating now!
2024-09-25 09:47:36 INFO     Epoch [60/200] train_loss: 4.0300, val_loss: 4.8499, lr: 0.001000, 53.38s
2024-09-25 09:48:21 INFO     epoch complete!
2024-09-25 09:48:21 INFO     evaluating now!
2024-09-25 09:48:28 INFO     Epoch [61/200] train_loss: 3.9705, val_loss: 4.8337, lr: 0.001000, 51.80s
2024-09-25 09:49:16 INFO     epoch complete!
2024-09-25 09:49:16 INFO     evaluating now!
2024-09-25 09:49:23 INFO     Epoch [62/200] train_loss: 4.0322, val_loss: 4.9458, lr: 0.001000, 55.54s
2024-09-25 09:50:12 INFO     epoch complete!
2024-09-25 09:50:12 INFO     evaluating now!
2024-09-25 09:50:19 INFO     Epoch [63/200] train_loss: 3.9746, val_loss: 5.2127, lr: 0.001000, 55.94s
2024-09-25 09:51:07 INFO     epoch complete!
2024-09-25 09:51:07 INFO     evaluating now!
2024-09-25 09:51:14 INFO     Epoch [64/200] train_loss: 3.9457, val_loss: 5.8931, lr: 0.001000, 54.92s
2024-09-25 09:52:02 INFO     epoch complete!
2024-09-25 09:52:02 INFO     evaluating now!
2024-09-25 09:52:09 INFO     Epoch [65/200] train_loss: 4.0761, val_loss: 4.8815, lr: 0.001000, 54.75s
2024-09-25 09:52:54 INFO     epoch complete!
2024-09-25 09:52:54 INFO     evaluating now!
2024-09-25 09:53:01 INFO     Epoch [66/200] train_loss: 3.9702, val_loss: 4.9136, lr: 0.001000, 51.88s
2024-09-25 09:53:45 INFO     epoch complete!
2024-09-25 09:53:45 INFO     evaluating now!
2024-09-25 09:53:52 INFO     Epoch [67/200] train_loss: 3.9214, val_loss: 4.8715, lr: 0.001000, 51.16s
2024-09-25 09:54:34 INFO     epoch complete!
2024-09-25 09:54:34 INFO     evaluating now!
2024-09-25 09:54:41 INFO     Epoch [68/200] train_loss: 3.9262, val_loss: 4.8115, lr: 0.001000, 48.91s
2024-09-25 09:55:27 INFO     epoch complete!
2024-09-25 09:55:27 INFO     evaluating now!
2024-09-25 09:55:34 INFO     Epoch [69/200] train_loss: 3.8803, val_loss: 4.8696, lr: 0.001000, 53.19s
2024-09-25 09:55:34 WARNING  Early stopping at epoch: 69
2024-09-25 09:55:34 INFO     Trained totally 70 epochs, average train time is 42.758s, average eval time is 6.127s
2024-09-25 09:55:34 INFO     Loaded model at 54
2024-09-25 09:55:34 INFO     Saved model at ./libcity/cache/100/model_cache/GWNET_CHITaxi20190406.m
2024-09-25 09:55:34 INFO     Start evaluating ...
2024-09-25 09:55:48 INFO     Note that you select the single mode to evaluate!
2024-09-25 09:55:48 INFO     Evaluate result is saved at ./libcity/cache/100/evaluate_cache\2024_09_25_09_55_48_GWNET_CHITaxi20190406.csv
2024-09-25 09:55:48 INFO     
         MAE       RMSE
1   2.290016   6.673280
2   2.371222   7.553401
3   2.595966   8.600071
4   2.759469   9.559998
5   2.933330  10.803996
6   3.083466  12.361514
7   3.246816  13.343005
8   3.375433  13.964606
9   3.339804  13.786786
10  3.361433  13.512639
11  3.466892  13.536870
12  3.602458  14.020613
2024-09-25 09:55:48 INFO     ----------------------------------------------------------------------------
2024-09-25 09:55:48 INFO     # 1, Kownledge Graph Embedding: None, Experiment ids: 101
2024-09-25 09:55:48 INFO     ----------------------------------------------------------------------------
2024-09-25 09:55:48 INFO     Begin pipeline, task=traffic_state_pred, model_name=GWNET, dataset_name=CHITaxi20190406, exp_id=101
2024-09-25 09:55:48 INFO     {'task': 'traffic_state_pred', 'model': 'GWNET', 'dataset': 'CHITaxi20190406', 'saved_model': True, 'train': True, 'exp_id': 100, 'max_epoch': 200, 'patience': 15, 'use_early_stop': True, 'cache_dataset': False, 'output_window': 12, 'metrics': ['MAE', 'RMSE'], 'cur_times': 1, 'dataset_class': 'TrafficStatePointDataset', 'executor': 'TrafficStateExecutor', 'evaluator': 'TrafficStateEvaluator', 'dropout': 0.3, 'blocks': 4, 'layers': 2, 'batch_size': 32, 'apt_layer': True, 'gcn_bool': True, 'adjtype': 'doubletransition', 'bidir_adj_mx': False, 'randomadj': True, 'kernel_size': 2, 'nhid': 32, 'residual_channels': 32, 'dilation_channels': 32, 'skip_channels': 256, 'end_channels': 512, 'scaler': 'standard', 'load_external': False, 'normal_external': False, 'ext_scaler': 'none', 'add_time_in_day': False, 'add_day_in_week': False, 'learner': 'adam', 'learning_rate': 0.001, 'lr_decay': False, 'clip_grad_norm': True, 'max_grad_norm': 5, 'use_rel_adj': True, 'use_apt_adj': True, 'num_workers': 0, 'pad_with_last_sample': True, 'train_rate': 0.7, 'eval_rate': 0.1, 'input_window': 12, 'robustness_test': False, 'noise_type': 'gaussian', 'disturb_rate': 0.5, 'noise_mean': [5], 'noise_SD': [10], 'gpu': True, 'gpu_id': 0, 'train_loss': 'none', 'epoch': 0, 'weight_decay': 0, 'lr_epsilon': 1e-08, 'lr_beta1': 0.9, 'lr_beta2': 0.999, 'lr_alpha': 0.99, 'lr_momentum': 0, 'lr_scheduler': 'multisteplr', 'lr_decay_ratio': 0.1, 'steps': [5, 20, 40, 70], 'step_size': 10, 'lr_T_max': 30, 'lr_eta_min': 0, 'lr_patience': 10, 'lr_threshold': 0.0001, 'log_level': 'INFO', 'log_every': 1, 'load_best_epoch': True, 'hyper_tune': False, 'evaluator_mode': 'single', 'save_mode': ['csv'], 'geo': {'including_types': ['Point'], 'Point': {}}, 'rel': {'including_types': ['geo'], 'geo': {'cost': 'num'}}, 'dyna': {'including_types': ['state'], 'state': {'entity_id': 'geo_id', 'traffic_speed': 'num'}}, 'data_col': ['inflow', 'outflow'], 'weight_col': 'cost', 'data_files': ['CHITaxi20190406'], 'geo_file': 'CHITaxi20190406', 'rel_file': 'CHITaxi20190406', 'output_dim': 2, 'time_intervals': 1800, 'init_weight_inf_or_zero': 'inf', 'set_weight_link_or_dist': 'dist', 'calculate_weight_adj': True, 'weight_adj_epsilon': 0.1, 'ke_type': 'area', 'device': device(type='cuda', index=0)}
2024-09-25 09:55:48 INFO     Loaded file CHITaxi20190406.geo, num_nodes=77
2024-09-25 09:55:48 INFO     set_weight_link_or_dist: dist
2024-09-25 09:55:48 INFO     init_weight_inf_or_zero: inf
2024-09-25 09:55:48 INFO     Loaded file CHITaxi20190406.rel, shape=(77, 77)
2024-09-25 09:55:48 INFO     Start Calculate the weight by Gauss kernel!
2024-09-25 09:55:48 INFO     Loading file CHITaxi20190406.dyna
2024-09-25 09:55:48 INFO     Loaded file CHITaxi20190406.dyna, shape=(4368, 77, 2)
2024-09-25 09:55:49 INFO     Dataset created
2024-09-25 09:55:49 INFO     x shape: (4345, 12, 77, 2), y shape: (4345, 12, 77, 2)
2024-09-25 09:55:49 INFO     train	x: (3042, 12, 77, 2), y: (3042, 12, 77, 2)
2024-09-25 09:55:49 INFO     eval	x: (434, 12, 77, 2), y: (434, 12, 77, 2)
2024-09-25 09:55:49 INFO     test	x: (869, 12, 77, 2), y: (869, 12, 77, 2)
2024-09-25 09:55:49 INFO     StandardScaler mean: 11.137838123415046, std: 53.15358218315973
2024-09-25 09:55:49 INFO     NoneScaler
2024-09-25 09:55:49 INFO     add adj_mx to supports
2024-09-25 09:55:49 INFO     add apt_adj(v1 * v2) in forward process
2024-09-25 09:55:49 INFO     receptive_field: 14
2024-09-25 09:55:49 INFO     GWNET(
  (filter_convs): ModuleList(
    (0): Conv2d(32, 32, kernel_size=(1, 2), stride=(1, 1))
    (1): Conv2d(32, 32, kernel_size=(1, 2), stride=(1, 1), dilation=(2, 2))
    (2): Conv2d(32, 32, kernel_size=(1, 2), stride=(1, 1))
    (3): Conv2d(32, 32, kernel_size=(1, 2), stride=(1, 1), dilation=(2, 2))
    (4): Conv2d(32, 32, kernel_size=(1, 2), stride=(1, 1))
    (5): Conv2d(32, 32, kernel_size=(1, 2), stride=(1, 1), dilation=(2, 2))
    (6): Conv2d(32, 32, kernel_size=(1, 2), stride=(1, 1))
    (7): Conv2d(32, 32, kernel_size=(1, 2), stride=(1, 1), dilation=(2, 2))
  )
  (gate_convs): ModuleList(
    (0): Conv1d(32, 32, kernel_size=(1, 2), stride=(1,))
    (1): Conv1d(32, 32, kernel_size=(1, 2), stride=(1,), dilation=(2,))
    (2): Conv1d(32, 32, kernel_size=(1, 2), stride=(1,))
    (3): Conv1d(32, 32, kernel_size=(1, 2), stride=(1,), dilation=(2,))
    (4): Conv1d(32, 32, kernel_size=(1, 2), stride=(1,))
    (5): Conv1d(32, 32, kernel_size=(1, 2), stride=(1,), dilation=(2,))
    (6): Conv1d(32, 32, kernel_size=(1, 2), stride=(1,))
    (7): Conv1d(32, 32, kernel_size=(1, 2), stride=(1,), dilation=(2,))
  )
  (residual_convs): ModuleList(
    (0): Conv1d(32, 32, kernel_size=(1, 1), stride=(1,))
    (1): Conv1d(32, 32, kernel_size=(1, 1), stride=(1,))
    (2): Conv1d(32, 32, kernel_size=(1, 1), stride=(1,))
    (3): Conv1d(32, 32, kernel_size=(1, 1), stride=(1,))
    (4): Conv1d(32, 32, kernel_size=(1, 1), stride=(1,))
    (5): Conv1d(32, 32, kernel_size=(1, 1), stride=(1,))
    (6): Conv1d(32, 32, kernel_size=(1, 1), stride=(1,))
    (7): Conv1d(32, 32, kernel_size=(1, 1), stride=(1,))
  )
  (skip_convs): ModuleList(
    (0): Conv1d(32, 256, kernel_size=(1, 1), stride=(1,))
    (1): Conv1d(32, 256, kernel_size=(1, 1), stride=(1,))
    (2): Conv1d(32, 256, kernel_size=(1, 1), stride=(1,))
    (3): Conv1d(32, 256, kernel_size=(1, 1), stride=(1,))
    (4): Conv1d(32, 256, kernel_size=(1, 1), stride=(1,))
    (5): Conv1d(32, 256, kernel_size=(1, 1), stride=(1,))
    (6): Conv1d(32, 256, kernel_size=(1, 1), stride=(1,))
    (7): Conv1d(32, 256, kernel_size=(1, 1), stride=(1,))
  )
  (bn): ModuleList(
    (0): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (gconv): ModuleList(
    (0): GCN(
      (nconv): NConv()
      (mlp): Linear(
        (mlp): Conv2d(224, 32, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (1): GCN(
      (nconv): NConv()
      (mlp): Linear(
        (mlp): Conv2d(224, 32, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (2): GCN(
      (nconv): NConv()
      (mlp): Linear(
        (mlp): Conv2d(224, 32, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (3): GCN(
      (nconv): NConv()
      (mlp): Linear(
        (mlp): Conv2d(224, 32, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (4): GCN(
      (nconv): NConv()
      (mlp): Linear(
        (mlp): Conv2d(224, 32, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (5): GCN(
      (nconv): NConv()
      (mlp): Linear(
        (mlp): Conv2d(224, 32, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (6): GCN(
      (nconv): NConv()
      (mlp): Linear(
        (mlp): Conv2d(224, 32, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (7): GCN(
      (nconv): NConv()
      (mlp): Linear(
        (mlp): Conv2d(224, 32, kernel_size=(1, 1), stride=(1, 1))
      )
    )
  )
  (start_conv): Conv2d(2, 32, kernel_size=(1, 1), stride=(1, 1))
  (end_conv_1): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))
  (end_conv_2): Conv2d(512, 12, kernel_size=(1, 1), stride=(1, 1))
)
2024-09-25 09:55:49 INFO     nodevec1	torch.Size([77, 10])	cuda:0	True
2024-09-25 09:55:49 INFO     nodevec2	torch.Size([10, 77])	cuda:0	True
2024-09-25 09:55:49 INFO     filter_convs.0.weight	torch.Size([32, 32, 1, 2])	cuda:0	True
2024-09-25 09:55:49 INFO     filter_convs.0.bias	torch.Size([32])	cuda:0	True
2024-09-25 09:55:49 INFO     filter_convs.1.weight	torch.Size([32, 32, 1, 2])	cuda:0	True
2024-09-25 09:55:49 INFO     filter_convs.1.bias	torch.Size([32])	cuda:0	True
2024-09-25 09:55:49 INFO     filter_convs.2.weight	torch.Size([32, 32, 1, 2])	cuda:0	True
2024-09-25 09:55:49 INFO     filter_convs.2.bias	torch.Size([32])	cuda:0	True
2024-09-25 09:55:49 INFO     filter_convs.3.weight	torch.Size([32, 32, 1, 2])	cuda:0	True
2024-09-25 09:55:49 INFO     filter_convs.3.bias	torch.Size([32])	cuda:0	True
2024-09-25 09:55:49 INFO     filter_convs.4.weight	torch.Size([32, 32, 1, 2])	cuda:0	True
2024-09-25 09:55:49 INFO     filter_convs.4.bias	torch.Size([32])	cuda:0	True
2024-09-25 09:55:49 INFO     filter_convs.5.weight	torch.Size([32, 32, 1, 2])	cuda:0	True
2024-09-25 09:55:49 INFO     filter_convs.5.bias	torch.Size([32])	cuda:0	True
2024-09-25 09:55:49 INFO     filter_convs.6.weight	torch.Size([32, 32, 1, 2])	cuda:0	True
2024-09-25 09:55:49 INFO     filter_convs.6.bias	torch.Size([32])	cuda:0	True
2024-09-25 09:55:49 INFO     filter_convs.7.weight	torch.Size([32, 32, 1, 2])	cuda:0	True
2024-09-25 09:55:49 INFO     filter_convs.7.bias	torch.Size([32])	cuda:0	True
2024-09-25 09:55:49 INFO     gate_convs.0.weight	torch.Size([32, 32, 1, 2])	cuda:0	True
2024-09-25 09:55:49 INFO     gate_convs.0.bias	torch.Size([32])	cuda:0	True
2024-09-25 09:55:49 INFO     gate_convs.1.weight	torch.Size([32, 32, 1, 2])	cuda:0	True
2024-09-25 09:55:49 INFO     gate_convs.1.bias	torch.Size([32])	cuda:0	True
2024-09-25 09:55:49 INFO     gate_convs.2.weight	torch.Size([32, 32, 1, 2])	cuda:0	True
2024-09-25 09:55:49 INFO     gate_convs.2.bias	torch.Size([32])	cuda:0	True
2024-09-25 09:55:49 INFO     gate_convs.3.weight	torch.Size([32, 32, 1, 2])	cuda:0	True
2024-09-25 09:55:49 INFO     gate_convs.3.bias	torch.Size([32])	cuda:0	True
2024-09-25 09:55:49 INFO     gate_convs.4.weight	torch.Size([32, 32, 1, 2])	cuda:0	True
2024-09-25 09:55:49 INFO     gate_convs.4.bias	torch.Size([32])	cuda:0	True
2024-09-25 09:55:49 INFO     gate_convs.5.weight	torch.Size([32, 32, 1, 2])	cuda:0	True
2024-09-25 09:55:49 INFO     gate_convs.5.bias	torch.Size([32])	cuda:0	True
2024-09-25 09:55:49 INFO     gate_convs.6.weight	torch.Size([32, 32, 1, 2])	cuda:0	True
2024-09-25 09:55:49 INFO     gate_convs.6.bias	torch.Size([32])	cuda:0	True
2024-09-25 09:55:49 INFO     gate_convs.7.weight	torch.Size([32, 32, 1, 2])	cuda:0	True
2024-09-25 09:55:49 INFO     gate_convs.7.bias	torch.Size([32])	cuda:0	True
2024-09-25 09:55:49 INFO     residual_convs.0.weight	torch.Size([32, 32, 1, 1])	cuda:0	True
2024-09-25 09:55:49 INFO     residual_convs.0.bias	torch.Size([32])	cuda:0	True
2024-09-25 09:55:49 INFO     residual_convs.1.weight	torch.Size([32, 32, 1, 1])	cuda:0	True
2024-09-25 09:55:49 INFO     residual_convs.1.bias	torch.Size([32])	cuda:0	True
2024-09-25 09:55:49 INFO     residual_convs.2.weight	torch.Size([32, 32, 1, 1])	cuda:0	True
2024-09-25 09:55:49 INFO     residual_convs.2.bias	torch.Size([32])	cuda:0	True
2024-09-25 09:55:49 INFO     residual_convs.3.weight	torch.Size([32, 32, 1, 1])	cuda:0	True
2024-09-25 09:55:49 INFO     residual_convs.3.bias	torch.Size([32])	cuda:0	True
2024-09-25 09:55:49 INFO     residual_convs.4.weight	torch.Size([32, 32, 1, 1])	cuda:0	True
2024-09-25 09:55:49 INFO     residual_convs.4.bias	torch.Size([32])	cuda:0	True
2024-09-25 09:55:49 INFO     residual_convs.5.weight	torch.Size([32, 32, 1, 1])	cuda:0	True
2024-09-25 09:55:49 INFO     residual_convs.5.bias	torch.Size([32])	cuda:0	True
2024-09-25 09:55:49 INFO     residual_convs.6.weight	torch.Size([32, 32, 1, 1])	cuda:0	True
2024-09-25 09:55:49 INFO     residual_convs.6.bias	torch.Size([32])	cuda:0	True
2024-09-25 09:55:49 INFO     residual_convs.7.weight	torch.Size([32, 32, 1, 1])	cuda:0	True
2024-09-25 09:55:49 INFO     residual_convs.7.bias	torch.Size([32])	cuda:0	True
2024-09-25 09:55:49 INFO     skip_convs.0.weight	torch.Size([256, 32, 1, 1])	cuda:0	True
2024-09-25 09:55:49 INFO     skip_convs.0.bias	torch.Size([256])	cuda:0	True
2024-09-25 09:55:49 INFO     skip_convs.1.weight	torch.Size([256, 32, 1, 1])	cuda:0	True
2024-09-25 09:55:49 INFO     skip_convs.1.bias	torch.Size([256])	cuda:0	True
2024-09-25 09:55:49 INFO     skip_convs.2.weight	torch.Size([256, 32, 1, 1])	cuda:0	True
2024-09-25 09:55:49 INFO     skip_convs.2.bias	torch.Size([256])	cuda:0	True
2024-09-25 09:55:49 INFO     skip_convs.3.weight	torch.Size([256, 32, 1, 1])	cuda:0	True
2024-09-25 09:55:49 INFO     skip_convs.3.bias	torch.Size([256])	cuda:0	True
2024-09-25 09:55:49 INFO     skip_convs.4.weight	torch.Size([256, 32, 1, 1])	cuda:0	True
2024-09-25 09:55:49 INFO     skip_convs.4.bias	torch.Size([256])	cuda:0	True
2024-09-25 09:55:49 INFO     skip_convs.5.weight	torch.Size([256, 32, 1, 1])	cuda:0	True
2024-09-25 09:55:49 INFO     skip_convs.5.bias	torch.Size([256])	cuda:0	True
2024-09-25 09:55:49 INFO     skip_convs.6.weight	torch.Size([256, 32, 1, 1])	cuda:0	True
2024-09-25 09:55:49 INFO     skip_convs.6.bias	torch.Size([256])	cuda:0	True
2024-09-25 09:55:49 INFO     skip_convs.7.weight	torch.Size([256, 32, 1, 1])	cuda:0	True
2024-09-25 09:55:49 INFO     skip_convs.7.bias	torch.Size([256])	cuda:0	True
2024-09-25 09:55:49 INFO     bn.0.weight	torch.Size([32])	cuda:0	True
2024-09-25 09:55:49 INFO     bn.0.bias	torch.Size([32])	cuda:0	True
2024-09-25 09:55:49 INFO     bn.1.weight	torch.Size([32])	cuda:0	True
2024-09-25 09:55:49 INFO     bn.1.bias	torch.Size([32])	cuda:0	True
2024-09-25 09:55:49 INFO     bn.2.weight	torch.Size([32])	cuda:0	True
2024-09-25 09:55:49 INFO     bn.2.bias	torch.Size([32])	cuda:0	True
2024-09-25 09:55:49 INFO     bn.3.weight	torch.Size([32])	cuda:0	True
2024-09-25 09:55:49 INFO     bn.3.bias	torch.Size([32])	cuda:0	True
2024-09-25 09:55:49 INFO     bn.4.weight	torch.Size([32])	cuda:0	True
2024-09-25 09:55:49 INFO     bn.4.bias	torch.Size([32])	cuda:0	True
2024-09-25 09:55:49 INFO     bn.5.weight	torch.Size([32])	cuda:0	True
2024-09-25 09:55:49 INFO     bn.5.bias	torch.Size([32])	cuda:0	True
2024-09-25 09:55:49 INFO     bn.6.weight	torch.Size([32])	cuda:0	True
2024-09-25 09:55:49 INFO     bn.6.bias	torch.Size([32])	cuda:0	True
2024-09-25 09:55:49 INFO     bn.7.weight	torch.Size([32])	cuda:0	True
2024-09-25 09:55:49 INFO     bn.7.bias	torch.Size([32])	cuda:0	True
2024-09-25 09:55:49 INFO     gconv.0.mlp.mlp.weight	torch.Size([32, 224, 1, 1])	cuda:0	True
2024-09-25 09:55:49 INFO     gconv.0.mlp.mlp.bias	torch.Size([32])	cuda:0	True
2024-09-25 09:55:49 INFO     gconv.1.mlp.mlp.weight	torch.Size([32, 224, 1, 1])	cuda:0	True
2024-09-25 09:55:49 INFO     gconv.1.mlp.mlp.bias	torch.Size([32])	cuda:0	True
2024-09-25 09:55:49 INFO     gconv.2.mlp.mlp.weight	torch.Size([32, 224, 1, 1])	cuda:0	True
2024-09-25 09:55:49 INFO     gconv.2.mlp.mlp.bias	torch.Size([32])	cuda:0	True
2024-09-25 09:55:49 INFO     gconv.3.mlp.mlp.weight	torch.Size([32, 224, 1, 1])	cuda:0	True
2024-09-25 09:55:49 INFO     gconv.3.mlp.mlp.bias	torch.Size([32])	cuda:0	True
2024-09-25 09:55:49 INFO     gconv.4.mlp.mlp.weight	torch.Size([32, 224, 1, 1])	cuda:0	True
2024-09-25 09:55:49 INFO     gconv.4.mlp.mlp.bias	torch.Size([32])	cuda:0	True
2024-09-25 09:55:49 INFO     gconv.5.mlp.mlp.weight	torch.Size([32, 224, 1, 1])	cuda:0	True
2024-09-25 09:55:49 INFO     gconv.5.mlp.mlp.bias	torch.Size([32])	cuda:0	True
2024-09-25 09:55:49 INFO     gconv.6.mlp.mlp.weight	torch.Size([32, 224, 1, 1])	cuda:0	True
2024-09-25 09:55:49 INFO     gconv.6.mlp.mlp.bias	torch.Size([32])	cuda:0	True
2024-09-25 09:55:49 INFO     gconv.7.mlp.mlp.weight	torch.Size([32, 224, 1, 1])	cuda:0	True
2024-09-25 09:55:49 INFO     gconv.7.mlp.mlp.bias	torch.Size([32])	cuda:0	True
2024-09-25 09:55:49 INFO     start_conv.weight	torch.Size([32, 2, 1, 1])	cuda:0	True
2024-09-25 09:55:49 INFO     start_conv.bias	torch.Size([32])	cuda:0	True
2024-09-25 09:55:49 INFO     end_conv_1.weight	torch.Size([512, 256, 1, 1])	cuda:0	True
2024-09-25 09:55:49 INFO     end_conv_1.bias	torch.Size([512])	cuda:0	True
2024-09-25 09:55:49 INFO     end_conv_2.weight	torch.Size([12, 512, 1, 1])	cuda:0	True
2024-09-25 09:55:49 INFO     end_conv_2.bias	torch.Size([12])	cuda:0	True
2024-09-25 09:55:49 INFO     Total parameter numbers: 306800
2024-09-25 09:55:49 INFO     You select `adam` optimizer.
2024-09-25 09:55:49 WARNING  Received none train loss func and will use the loss func defined in the model.
2024-09-25 09:55:49 INFO     Start training ...
2024-09-25 09:55:49 INFO     num_batches:96
2024-09-25 09:56:39 INFO     epoch complete!
2024-09-25 09:56:39 INFO     evaluating now!
2024-09-25 09:56:46 INFO     Epoch [0/200] train_loss: 12.2268, val_loss: 11.8510, lr: 0.001000, 57.31s
2024-09-25 09:56:46 INFO     Saved model at 0
2024-09-25 09:56:46 INFO     Val loss decrease from inf to 11.8510, saving to ./libcity/cache/100/model_cache/GWNET_CHITaxi20190406_epoch0.tar
2024-09-25 09:57:34 INFO     epoch complete!
2024-09-25 09:57:34 INFO     evaluating now!
2024-09-25 09:57:40 INFO     Epoch [1/200] train_loss: 9.1982, val_loss: 8.9318, lr: 0.001000, 53.69s
2024-09-25 09:57:40 INFO     Saved model at 1
2024-09-25 09:57:40 INFO     Val loss decrease from 11.8510 to 8.9318, saving to ./libcity/cache/100/model_cache/GWNET_CHITaxi20190406_epoch1.tar
2024-09-25 09:58:26 INFO     epoch complete!
2024-09-25 09:58:26 INFO     evaluating now!
2024-09-25 09:58:33 INFO     Epoch [2/200] train_loss: 8.3356, val_loss: 8.4576, lr: 0.001000, 53.05s
2024-09-25 09:58:33 INFO     Saved model at 2
2024-09-25 09:58:33 INFO     Val loss decrease from 8.9318 to 8.4576, saving to ./libcity/cache/100/model_cache/GWNET_CHITaxi20190406_epoch2.tar
2024-09-25 09:59:20 INFO     epoch complete!
2024-09-25 09:59:20 INFO     evaluating now!
2024-09-25 09:59:27 INFO     Epoch [3/200] train_loss: 8.0171, val_loss: 8.1632, lr: 0.001000, 54.55s
2024-09-25 09:59:27 INFO     Saved model at 3
2024-09-25 09:59:27 INFO     Val loss decrease from 8.4576 to 8.1632, saving to ./libcity/cache/100/model_cache/GWNET_CHITaxi20190406_epoch3.tar
2024-09-25 10:00:16 INFO     epoch complete!
2024-09-25 10:00:16 INFO     evaluating now!
2024-09-25 10:00:23 INFO     Epoch [4/200] train_loss: 7.7760, val_loss: 8.2960, lr: 0.001000, 55.54s
2024-09-25 10:01:11 INFO     epoch complete!
2024-09-25 10:01:11 INFO     evaluating now!
2024-09-25 10:01:18 INFO     Epoch [5/200] train_loss: 7.8300, val_loss: 8.6748, lr: 0.001000, 55.38s
2024-09-25 10:02:07 INFO     epoch complete!
2024-09-25 10:02:07 INFO     evaluating now!
2024-09-25 10:02:13 INFO     Epoch [6/200] train_loss: 7.4371, val_loss: 8.4491, lr: 0.001000, 54.49s
2024-09-25 10:03:02 INFO     epoch complete!
2024-09-25 10:03:02 INFO     evaluating now!
2024-09-25 10:03:07 INFO     Epoch [7/200] train_loss: 7.4366, val_loss: 7.9601, lr: 0.001000, 54.61s
2024-09-25 10:03:07 INFO     Saved model at 7
2024-09-25 10:03:07 INFO     Val loss decrease from 8.1632 to 7.9601, saving to ./libcity/cache/100/model_cache/GWNET_CHITaxi20190406_epoch7.tar
2024-09-25 10:03:55 INFO     epoch complete!
2024-09-25 10:03:55 INFO     evaluating now!
2024-09-25 10:04:00 INFO     Epoch [8/200] train_loss: 6.8973, val_loss: 6.6482, lr: 0.001000, 52.95s
2024-09-25 10:04:00 INFO     Saved model at 8
2024-09-25 10:04:00 INFO     Val loss decrease from 7.9601 to 6.6482, saving to ./libcity/cache/100/model_cache/GWNET_CHITaxi20190406_epoch8.tar
2024-09-25 10:04:47 INFO     epoch complete!
2024-09-25 10:04:47 INFO     evaluating now!
2024-09-25 10:04:53 INFO     Epoch [9/200] train_loss: 6.2454, val_loss: 6.4636, lr: 0.001000, 52.80s
2024-09-25 10:04:53 INFO     Saved model at 9
2024-09-25 10:04:53 INFO     Val loss decrease from 6.6482 to 6.4636, saving to ./libcity/cache/100/model_cache/GWNET_CHITaxi20190406_epoch9.tar
2024-09-25 10:05:41 INFO     epoch complete!
2024-09-25 10:05:41 INFO     evaluating now!
2024-09-25 10:05:49 INFO     Epoch [10/200] train_loss: 5.8450, val_loss: 6.4489, lr: 0.001000, 55.29s
2024-09-25 10:05:49 INFO     Saved model at 10
2024-09-25 10:05:49 INFO     Val loss decrease from 6.4636 to 6.4489, saving to ./libcity/cache/100/model_cache/GWNET_CHITaxi20190406_epoch10.tar
2024-09-25 10:06:36 INFO     epoch complete!
2024-09-25 10:06:36 INFO     evaluating now!
2024-09-25 10:06:43 INFO     Epoch [11/200] train_loss: 5.6441, val_loss: 6.4967, lr: 0.001000, 54.16s
2024-09-25 10:07:30 INFO     epoch complete!
2024-09-25 10:07:30 INFO     evaluating now!
2024-09-25 10:07:36 INFO     Epoch [12/200] train_loss: 5.4273, val_loss: 6.1262, lr: 0.001000, 53.31s
2024-09-25 10:07:36 INFO     Saved model at 12
2024-09-25 10:07:36 INFO     Val loss decrease from 6.4489 to 6.1262, saving to ./libcity/cache/100/model_cache/GWNET_CHITaxi20190406_epoch12.tar
2024-09-25 10:08:24 INFO     epoch complete!
2024-09-25 10:08:24 INFO     evaluating now!
2024-09-25 10:08:32 INFO     Epoch [13/200] train_loss: 5.4151, val_loss: 6.4831, lr: 0.001000, 55.57s
2024-09-25 10:09:22 INFO     epoch complete!
2024-09-25 10:09:22 INFO     evaluating now!
2024-09-25 10:09:29 INFO     Epoch [14/200] train_loss: 5.2381, val_loss: 5.6326, lr: 0.001000, 57.51s
2024-09-25 10:09:29 INFO     Saved model at 14
2024-09-25 10:09:29 INFO     Val loss decrease from 6.1262 to 5.6326, saving to ./libcity/cache/100/model_cache/GWNET_CHITaxi20190406_epoch14.tar
2024-09-25 10:10:18 INFO     epoch complete!
2024-09-25 10:10:18 INFO     evaluating now!
2024-09-25 10:10:24 INFO     Epoch [15/200] train_loss: 5.2143, val_loss: 5.5926, lr: 0.001000, 54.36s
2024-09-25 10:10:24 INFO     Saved model at 15
2024-09-25 10:10:24 INFO     Val loss decrease from 5.6326 to 5.5926, saving to ./libcity/cache/100/model_cache/GWNET_CHITaxi20190406_epoch15.tar
2024-09-25 10:11:11 INFO     epoch complete!
2024-09-25 10:11:11 INFO     evaluating now!
2024-09-25 10:11:18 INFO     Epoch [16/200] train_loss: 5.0857, val_loss: 5.9472, lr: 0.001000, 54.97s
2024-09-25 10:12:06 INFO     epoch complete!
2024-09-25 10:12:06 INFO     evaluating now!
2024-09-25 10:12:14 INFO     Epoch [17/200] train_loss: 4.9792, val_loss: 5.3515, lr: 0.001000, 55.02s
2024-09-25 10:12:14 INFO     Saved model at 17
2024-09-25 10:12:14 INFO     Val loss decrease from 5.5926 to 5.3515, saving to ./libcity/cache/100/model_cache/GWNET_CHITaxi20190406_epoch17.tar
2024-09-25 10:13:02 INFO     epoch complete!
2024-09-25 10:13:02 INFO     evaluating now!
2024-09-25 10:13:08 INFO     Epoch [18/200] train_loss: 4.9719, val_loss: 7.4383, lr: 0.001000, 53.97s
2024-09-25 10:13:56 INFO     epoch complete!
2024-09-25 10:13:56 INFO     evaluating now!
2024-09-25 10:14:03 INFO     Epoch [19/200] train_loss: 4.9275, val_loss: 5.5759, lr: 0.001000, 55.70s
2024-09-25 10:14:51 INFO     epoch complete!
2024-09-25 10:14:51 INFO     evaluating now!
2024-09-25 10:14:59 INFO     Epoch [20/200] train_loss: 4.8553, val_loss: 5.6953, lr: 0.001000, 55.33s
2024-09-25 10:15:46 INFO     epoch complete!
2024-09-25 10:15:46 INFO     evaluating now!
2024-09-25 10:15:53 INFO     Epoch [21/200] train_loss: 4.7802, val_loss: 6.0844, lr: 0.001000, 54.94s
2024-09-25 10:16:38 INFO     epoch complete!
2024-09-25 10:16:38 INFO     evaluating now!
2024-09-25 10:16:44 INFO     Epoch [22/200] train_loss: 4.8329, val_loss: 5.0630, lr: 0.001000, 50.95s
2024-09-25 10:16:44 INFO     Saved model at 22
2024-09-25 10:16:44 INFO     Val loss decrease from 5.3515 to 5.0630, saving to ./libcity/cache/100/model_cache/GWNET_CHITaxi20190406_epoch22.tar
2024-09-25 10:17:28 INFO     epoch complete!
2024-09-25 10:17:28 INFO     evaluating now!
2024-09-25 10:17:35 INFO     Epoch [23/200] train_loss: 4.7592, val_loss: 5.2222, lr: 0.001000, 50.52s
2024-09-25 10:18:19 INFO     epoch complete!
2024-09-25 10:18:19 INFO     evaluating now!
2024-09-25 10:18:25 INFO     Epoch [24/200] train_loss: 4.6898, val_loss: 5.4382, lr: 0.001000, 50.42s
2024-09-25 10:19:13 INFO     epoch complete!
2024-09-25 10:19:13 INFO     evaluating now!
2024-09-25 10:19:20 INFO     Epoch [25/200] train_loss: 4.6393, val_loss: 5.9975, lr: 0.001000, 54.48s
2024-09-25 10:20:08 INFO     epoch complete!
2024-09-25 10:20:08 INFO     evaluating now!
2024-09-25 10:20:15 INFO     Epoch [26/200] train_loss: 4.6097, val_loss: 5.7247, lr: 0.001000, 54.82s
2024-09-25 10:21:04 INFO     epoch complete!
2024-09-25 10:21:04 INFO     evaluating now!
2024-09-25 10:21:11 INFO     Epoch [27/200] train_loss: 4.6661, val_loss: 5.5158, lr: 0.001000, 56.12s
2024-09-25 10:21:58 INFO     epoch complete!
2024-09-25 10:21:58 INFO     evaluating now!
2024-09-25 10:22:05 INFO     Epoch [28/200] train_loss: 4.6091, val_loss: 5.2048, lr: 0.001000, 54.10s
2024-09-25 10:22:53 INFO     epoch complete!
2024-09-25 10:22:53 INFO     evaluating now!
2024-09-25 10:23:01 INFO     Epoch [29/200] train_loss: 4.5302, val_loss: 5.0389, lr: 0.001000, 55.63s
2024-09-25 10:23:01 INFO     Saved model at 29
2024-09-25 10:23:01 INFO     Val loss decrease from 5.0630 to 5.0389, saving to ./libcity/cache/100/model_cache/GWNET_CHITaxi20190406_epoch29.tar
2024-09-25 10:23:48 INFO     epoch complete!
2024-09-25 10:23:48 INFO     evaluating now!
2024-09-25 10:23:55 INFO     Epoch [30/200] train_loss: 4.5737, val_loss: 5.6293, lr: 0.001000, 54.51s
2024-09-25 10:24:43 INFO     epoch complete!
2024-09-25 10:24:43 INFO     evaluating now!
2024-09-25 10:24:50 INFO     Epoch [31/200] train_loss: 4.5367, val_loss: 4.9693, lr: 0.001000, 55.30s
2024-09-25 10:24:50 INFO     Saved model at 31
2024-09-25 10:24:50 INFO     Val loss decrease from 5.0389 to 4.9693, saving to ./libcity/cache/100/model_cache/GWNET_CHITaxi20190406_epoch31.tar
2024-09-25 10:25:38 INFO     epoch complete!
2024-09-25 10:25:38 INFO     evaluating now!
2024-09-25 10:25:45 INFO     Epoch [32/200] train_loss: 4.4534, val_loss: 5.0136, lr: 0.001000, 54.46s
2024-09-25 10:26:32 INFO     epoch complete!
2024-09-25 10:26:32 INFO     evaluating now!
2024-09-25 10:26:37 INFO     Epoch [33/200] train_loss: 4.4417, val_loss: 5.3495, lr: 0.001000, 52.43s
2024-09-25 10:27:23 INFO     epoch complete!
2024-09-25 10:27:23 INFO     evaluating now!
2024-09-25 10:27:30 INFO     Epoch [34/200] train_loss: 4.4309, val_loss: 5.3861, lr: 0.001000, 53.16s
2024-09-25 10:28:17 INFO     epoch complete!
2024-09-25 10:28:17 INFO     evaluating now!
2024-09-25 10:28:24 INFO     Epoch [35/200] train_loss: 4.4095, val_loss: 5.2930, lr: 0.001000, 53.47s
2024-09-25 10:29:11 INFO     epoch complete!
2024-09-25 10:29:11 INFO     evaluating now!
2024-09-25 10:29:18 INFO     Epoch [36/200] train_loss: 4.3240, val_loss: 5.6594, lr: 0.001000, 53.78s
2024-09-25 10:30:05 INFO     epoch complete!
2024-09-25 10:30:05 INFO     evaluating now!
2024-09-25 10:30:12 INFO     Epoch [37/200] train_loss: 4.3540, val_loss: 6.1437, lr: 0.001000, 54.73s
2024-09-25 10:30:59 INFO     epoch complete!
2024-09-25 10:30:59 INFO     evaluating now!
2024-09-25 10:31:06 INFO     Epoch [38/200] train_loss: 4.3854, val_loss: 4.9468, lr: 0.001000, 53.57s
2024-09-25 10:31:06 INFO     Saved model at 38
2024-09-25 10:31:06 INFO     Val loss decrease from 4.9693 to 4.9468, saving to ./libcity/cache/100/model_cache/GWNET_CHITaxi20190406_epoch38.tar
2024-09-25 10:31:54 INFO     epoch complete!
2024-09-25 10:31:54 INFO     evaluating now!
2024-09-25 10:32:02 INFO     Epoch [39/200] train_loss: 4.3007, val_loss: 4.8729, lr: 0.001000, 55.53s
2024-09-25 10:32:02 INFO     Saved model at 39
2024-09-25 10:32:02 INFO     Val loss decrease from 4.9468 to 4.8729, saving to ./libcity/cache/100/model_cache/GWNET_CHITaxi20190406_epoch39.tar
2024-09-25 10:32:51 INFO     epoch complete!
2024-09-25 10:32:51 INFO     evaluating now!
2024-09-25 10:32:57 INFO     Epoch [40/200] train_loss: 4.2740, val_loss: 5.0248, lr: 0.001000, 55.41s
2024-09-25 10:33:46 INFO     epoch complete!
2024-09-25 10:33:46 INFO     evaluating now!
2024-09-25 10:33:52 INFO     Epoch [41/200] train_loss: 4.2605, val_loss: 5.0921, lr: 0.001000, 54.81s
2024-09-25 10:34:40 INFO     epoch complete!
2024-09-25 10:34:40 INFO     evaluating now!
2024-09-25 10:34:47 INFO     Epoch [42/200] train_loss: 4.2612, val_loss: 5.2112, lr: 0.001000, 54.91s
2024-09-25 10:35:38 INFO     epoch complete!
2024-09-25 10:35:38 INFO     evaluating now!
2024-09-25 10:35:43 INFO     Epoch [43/200] train_loss: 4.2495, val_loss: 5.2255, lr: 0.001000, 56.23s
2024-09-25 10:36:30 INFO     epoch complete!
2024-09-25 10:36:30 INFO     evaluating now!
2024-09-25 10:36:37 INFO     Epoch [44/200] train_loss: 4.2189, val_loss: 4.8412, lr: 0.001000, 53.90s
2024-09-25 10:36:37 INFO     Saved model at 44
2024-09-25 10:36:37 INFO     Val loss decrease from 4.8729 to 4.8412, saving to ./libcity/cache/100/model_cache/GWNET_CHITaxi20190406_epoch44.tar
2024-09-25 10:37:23 INFO     epoch complete!
2024-09-25 10:37:23 INFO     evaluating now!
2024-09-25 10:37:30 INFO     Epoch [45/200] train_loss: 4.1688, val_loss: 5.9017, lr: 0.001000, 52.95s
2024-09-25 10:38:16 INFO     epoch complete!
2024-09-25 10:38:16 INFO     evaluating now!
2024-09-25 10:38:23 INFO     Epoch [46/200] train_loss: 4.1484, val_loss: 5.0296, lr: 0.001000, 52.68s
2024-09-25 10:39:10 INFO     epoch complete!
2024-09-25 10:39:10 INFO     evaluating now!
2024-09-25 10:39:17 INFO     Epoch [47/200] train_loss: 4.1299, val_loss: 5.5064, lr: 0.001000, 54.23s
2024-09-25 10:40:04 INFO     epoch complete!
2024-09-25 10:40:04 INFO     evaluating now!
2024-09-25 10:40:11 INFO     Epoch [48/200] train_loss: 4.1197, val_loss: 5.5855, lr: 0.001000, 54.16s
2024-09-25 10:41:01 INFO     epoch complete!
2024-09-25 10:41:01 INFO     evaluating now!
2024-09-25 10:41:09 INFO     Epoch [49/200] train_loss: 4.1497, val_loss: 5.5906, lr: 0.001000, 58.32s
2024-09-25 10:41:59 INFO     epoch complete!
2024-09-25 10:41:59 INFO     evaluating now!
2024-09-25 10:42:05 INFO     Epoch [50/200] train_loss: 4.0797, val_loss: 4.9804, lr: 0.001000, 55.58s
2024-09-25 10:42:53 INFO     epoch complete!
2024-09-25 10:42:53 INFO     evaluating now!
2024-09-25 10:43:00 INFO     Epoch [51/200] train_loss: 4.0822, val_loss: 5.1177, lr: 0.001000, 55.26s
2024-09-25 10:43:49 INFO     epoch complete!
2024-09-25 10:43:49 INFO     evaluating now!
2024-09-25 10:43:57 INFO     Epoch [52/200] train_loss: 4.0760, val_loss: 4.7704, lr: 0.001000, 57.38s
2024-09-25 10:43:57 INFO     Saved model at 52
2024-09-25 10:43:57 INFO     Val loss decrease from 4.8412 to 4.7704, saving to ./libcity/cache/100/model_cache/GWNET_CHITaxi20190406_epoch52.tar
2024-09-25 10:44:46 INFO     epoch complete!
2024-09-25 10:44:46 INFO     evaluating now!
2024-09-25 10:44:55 INFO     Epoch [53/200] train_loss: 4.0895, val_loss: 5.0009, lr: 0.001000, 57.39s
2024-09-25 10:45:45 INFO     epoch complete!
2024-09-25 10:45:45 INFO     evaluating now!
2024-09-25 10:45:52 INFO     Epoch [54/200] train_loss: 4.0334, val_loss: 5.4309, lr: 0.001000, 57.54s
2024-09-25 10:46:41 INFO     epoch complete!
2024-09-25 10:46:41 INFO     evaluating now!
2024-09-25 10:46:49 INFO     Epoch [55/200] train_loss: 4.0524, val_loss: 5.7709, lr: 0.001000, 56.98s
2024-09-25 10:47:42 INFO     epoch complete!
2024-09-25 10:47:42 INFO     evaluating now!
2024-09-25 10:47:50 INFO     Epoch [56/200] train_loss: 4.0228, val_loss: 5.1456, lr: 0.001000, 60.73s
2024-09-25 10:48:40 INFO     epoch complete!
2024-09-25 10:48:40 INFO     evaluating now!
2024-09-25 10:48:47 INFO     Epoch [57/200] train_loss: 4.0329, val_loss: 4.9937, lr: 0.001000, 57.11s
2024-09-25 10:49:34 INFO     epoch complete!
2024-09-25 10:49:34 INFO     evaluating now!
2024-09-25 10:49:41 INFO     Epoch [58/200] train_loss: 4.0340, val_loss: 5.4754, lr: 0.001000, 53.67s
2024-09-25 10:50:27 INFO     epoch complete!
2024-09-25 10:50:27 INFO     evaluating now!
2024-09-25 10:50:35 INFO     Epoch [59/200] train_loss: 3.9914, val_loss: 5.1240, lr: 0.001000, 54.03s
2024-09-25 10:51:27 INFO     epoch complete!
2024-09-25 10:51:27 INFO     evaluating now!
2024-09-25 10:51:36 INFO     Epoch [60/200] train_loss: 3.9605, val_loss: 4.9727, lr: 0.001000, 60.80s
2024-09-25 10:52:28 INFO     epoch complete!
2024-09-25 10:52:28 INFO     evaluating now!
2024-09-25 10:52:35 INFO     Epoch [61/200] train_loss: 3.9624, val_loss: 4.7977, lr: 0.001000, 59.39s
2024-09-25 10:53:24 INFO     epoch complete!
2024-09-25 10:53:24 INFO     evaluating now!
2024-09-25 10:53:31 INFO     Epoch [62/200] train_loss: 3.9540, val_loss: 5.0287, lr: 0.001000, 55.51s
2024-09-25 10:54:18 INFO     epoch complete!
2024-09-25 10:54:18 INFO     evaluating now!
2024-09-25 10:54:25 INFO     Epoch [63/200] train_loss: 3.9182, val_loss: 5.5553, lr: 0.001000, 54.01s
2024-09-25 10:55:12 INFO     epoch complete!
2024-09-25 10:55:12 INFO     evaluating now!
2024-09-25 10:55:18 INFO     Epoch [64/200] train_loss: 3.9110, val_loss: 4.9326, lr: 0.001000, 53.70s
2024-09-25 10:56:07 INFO     epoch complete!
2024-09-25 10:56:07 INFO     evaluating now!
2024-09-25 10:56:15 INFO     Epoch [65/200] train_loss: 3.9205, val_loss: 4.9856, lr: 0.001000, 56.70s
2024-09-25 10:57:01 INFO     epoch complete!
2024-09-25 10:57:01 INFO     evaluating now!
2024-09-25 10:57:08 INFO     Epoch [66/200] train_loss: 3.8979, val_loss: 4.8633, lr: 0.001000, 52.89s
2024-09-25 10:57:57 INFO     epoch complete!
2024-09-25 10:57:57 INFO     evaluating now!
2024-09-25 10:58:04 INFO     Epoch [67/200] train_loss: 3.8769, val_loss: 4.8784, lr: 0.001000, 55.96s
2024-09-25 10:58:04 WARNING  Early stopping at epoch: 67
2024-09-25 10:58:04 INFO     Trained totally 68 epochs, average train time is 47.994s, average eval time is 6.928s
2024-09-25 10:58:04 INFO     Loaded model at 52
2024-09-25 10:58:04 INFO     Saved model at ./libcity/cache/101/model_cache/GWNET_CHITaxi20190406.m
